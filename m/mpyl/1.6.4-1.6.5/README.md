# Comparing `tmp/mpyl-1.6.4-py3-none-any.whl.zip` & `tmp/mpyl-1.6.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,114 +1,122 @@
-Zip file size: 257958 bytes, number of entries: 112
--rw-r--r--  2.0 unx     1278 b- defN 24-Apr-17 10:57 mpyl/__init__.py
--rw-r--r--  2.0 unx      215 b- defN 24-Apr-17 10:57 mpyl/__main__.py
--rw-r--r--  2.0 unx     7535 b- defN 24-Apr-17 10:57 mpyl/build.py
--rw-r--r--  2.0 unx      304 b- defN 24-Apr-17 10:57 mpyl/constants.py
--rw-r--r--  2.0 unx    20750 b- defN 24-Apr-17 10:57 mpyl/project.py
--rw-r--r--  2.0 unx      574 b- defN 24-Apr-17 10:57 mpyl/project_execution.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-17 10:57 mpyl/py.typed
--rw-r--r--  2.0 unx      681 b- defN 24-Apr-17 10:57 mpyl/run_plan.py
--rw-r--r--  2.0 unx     2370 b- defN 24-Apr-17 10:57 mpyl/validation.py
--rw-r--r--  2.0 unx       60 b- defN 24-Apr-17 10:57 mpyl/artifacts/__init__.py
--rw-r--r--  2.0 unx     9222 b- defN 24-Apr-17 10:57 mpyl/artifacts/build_artifacts.py
--rw-r--r--  2.0 unx     3512 b- defN 24-Apr-17 10:57 mpyl/cli/__init__.py
--rw-r--r--  2.0 unx    18085 b- defN 24-Apr-17 10:57 mpyl/cli/build.py
--rw-r--r--  2.0 unx      614 b- defN 24-Apr-17 10:57 mpyl/cli/health.py
--rw-r--r--  2.0 unx     2417 b- defN 24-Apr-17 10:57 mpyl/cli/meta_info.py
--rw-r--r--  2.0 unx     8536 b- defN 24-Apr-17 10:57 mpyl/cli/projects.py
--rw-r--r--  2.0 unx     7944 b- defN 24-Apr-17 10:57 mpyl/cli/repository.py
--rw-r--r--  2.0 unx       34 b- defN 24-Apr-17 10:57 mpyl/cli/commands/__init__.py
--rw-r--r--  2.0 unx      425 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/__init__.py
--rw-r--r--  2.0 unx     1261 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/artifacts.py
--rw-r--r--  2.0 unx     4524 b- defN 24-Apr-17 10:57 mpyl/cli/commands/build/jenkins.py
--rw-r--r--  2.0 unx       38 b- defN 24-Apr-17 10:57 mpyl/cli/commands/health/__init__.py
--rw-r--r--  2.0 unx     8248 b- defN 24-Apr-17 10:57 mpyl/cli/commands/health/checks.py
--rw-r--r--  2.0 unx       52 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/__init__.py
--rw-r--r--  2.0 unx     1771 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/formatting.py
--rw-r--r--  2.0 unx     6356 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/lint.py
--rw-r--r--  2.0 unx      659 b- defN 24-Apr-17 10:57 mpyl/cli/commands/projects/upgrade.py
--rw-r--r--  2.0 unx      620 b- defN 24-Apr-17 10:57 mpyl/projects/__init__.py
--rw-r--r--  2.0 unx     2006 b- defN 24-Apr-17 10:57 mpyl/projects/find.py
--rw-r--r--  2.0 unx    12121 b- defN 24-Apr-17 10:57 mpyl/projects/versioning.py
--rw-r--r--  2.0 unx      333 b- defN 24-Apr-17 10:57 mpyl/projects/releases/releases.txt
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 10:57 mpyl/reporting/__init__.py
--rw-r--r--  2.0 unx       76 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/__init__.py
--rw-r--r--  2.0 unx     5797 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/markdown.py
--rw-r--r--  2.0 unx     1340 b- defN 24-Apr-17 10:57 mpyl/reporting/formatting/text.py
--rw-r--r--  2.0 unx     1139 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/__init__.py
--rw-r--r--  2.0 unx     8932 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/github.py
--rw-r--r--  2.0 unx     9568 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/jira.py
--rw-r--r--  2.0 unx     8064 b- defN 24-Apr-17 10:57 mpyl/reporting/targets/slack.py
--rw-r--r--  2.0 unx    11326 b- defN 24-Apr-17 10:57 mpyl/schema/k8s_api_core.schema.yml
--rw-r--r--  2.0 unx    12912 b- defN 24-Apr-17 10:57 mpyl/schema/mpyl_config.schema.yml
--rw-r--r--  2.0 unx    24550 b- defN 24-Apr-17 10:57 mpyl/schema/project.schema.yml
--rw-r--r--  2.0 unx     3296 b- defN 24-Apr-17 10:57 mpyl/schema/run_properties.schema.yml
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-17 10:57 mpyl/stages/__init__.py
--rw-r--r--  2.0 unx    10713 b- defN 24-Apr-17 10:57 mpyl/stages/discovery.py
--rw-r--r--  2.0 unx     6456 b- defN 24-Apr-17 10:57 mpyl/steps/__init__.py
--rw-r--r--  2.0 unx     2686 b- defN 24-Apr-17 10:57 mpyl/steps/collection.py
--rw-r--r--  2.0 unx     8460 b- defN 24-Apr-17 10:57 mpyl/steps/models.py
--rw-r--r--  2.0 unx     4320 b- defN 24-Apr-17 10:57 mpyl/steps/run.py
--rw-r--r--  2.0 unx     3376 b- defN 24-Apr-17 10:57 mpyl/steps/run_properties.py
--rw-r--r--  2.0 unx     9692 b- defN 24-Apr-17 10:57 mpyl/steps/steps.py
--rw-r--r--  2.0 unx       80 b- defN 24-Apr-17 10:57 mpyl/steps/build/__init__.py
--rw-r--r--  2.0 unx     5034 b- defN 24-Apr-17 10:57 mpyl/steps/build/docker_build.py
--rw-r--r--  2.0 unx     1195 b- defN 24-Apr-17 10:57 mpyl/steps/build/echo.py
--rw-r--r--  2.0 unx     2187 b- defN 24-Apr-17 10:57 mpyl/steps/build/post_docker_build.py
--rw-r--r--  2.0 unx     2714 b- defN 24-Apr-17 10:57 mpyl/steps/build/sbt.py
--rw-r--r--  2.0 unx      884 b- defN 24-Apr-17 10:57 mpyl/steps/build/skip.py
--rw-r--r--  2.0 unx       82 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/__init__.py
--rw-r--r--  2.0 unx     7596 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/dagster.py
--rw-r--r--  2.0 unx     1078 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/echo.py
--rw-r--r--  2.0 unx     1533 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/ephemeral_docker_deploy.py
--rw-r--r--  2.0 unx     3221 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes.py
--rw-r--r--  2.0 unx     1115 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes_job.py
--rw-r--r--  2.0 unx     1188 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/kubernetes_spark_job.py
--rw-r--r--  2.0 unx    11433 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/__init__.py
--rw-r--r--  2.0 unx    28949 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/chart.py
--rw-r--r--  2.0 unx     1276 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/deploy_config.py
--rw-r--r--  2.0 unx     5080 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/helm.py
--rw-r--r--  2.0 unx     1594 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/rancher.py
--rw-r--r--  2.0 unx     4868 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/__init__.py
--rw-r--r--  2.0 unx     3368 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/dagster.py
--rw-r--r--  2.0 unx     2260 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/prometheus.py
--rw-r--r--  2.0 unx      616 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/sealed_secret.py
--rw-r--r--  2.0 unx     5895 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/spark.py
--rw-r--r--  2.0 unx     2818 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/traefik.py
--rw-r--r--  2.0 unx   582312 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
--rw-r--r--  2.0 unx    39299 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
--rw-r--r--  2.0 unx   168371 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
--rw-r--r--  2.0 unx   151469 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
--rw-r--r--  2.0 unx    11703 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
--rw-r--r--  2.0 unx    42950 b- defN 24-Apr-17 10:57 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
--rw-r--r--  2.0 unx       90 b- defN 24-Apr-17 10:57 mpyl/steps/postdeploy/__init__.py
--rw-r--r--  2.0 unx     8518 b- defN 24-Apr-17 10:57 mpyl/steps/postdeploy/cypress_test.py
--rw-r--r--  2.0 unx       78 b- defN 24-Apr-17 10:57 mpyl/steps/test/__init__.py
--rw-r--r--  2.0 unx     1574 b- defN 24-Apr-17 10:57 mpyl/steps/test/after_test.py
--rw-r--r--  2.0 unx     4153 b- defN 24-Apr-17 10:57 mpyl/steps/test/before_test.py
--rw-r--r--  2.0 unx     4652 b- defN 24-Apr-17 10:57 mpyl/steps/test/dockertest.py
--rw-r--r--  2.0 unx     1937 b- defN 24-Apr-17 10:57 mpyl/steps/test/echo.py
--rw-r--r--  2.0 unx     4622 b- defN 24-Apr-17 10:57 mpyl/steps/test/sbt.py
--rw-r--r--  2.0 unx      878 b- defN 24-Apr-17 10:57 mpyl/steps/test/skip.py
--rw-r--r--  2.0 unx      346 b- defN 24-Apr-17 10:57 mpyl/utilities/__init__.py
--rw-r--r--  2.0 unx      953 b- defN 24-Apr-17 10:57 mpyl/utilities/cypress/__init__.py
--rw-r--r--  2.0 unx     1068 b- defN 24-Apr-17 10:57 mpyl/utilities/dagster/__init__.py
--rw-r--r--  2.0 unx    13237 b- defN 24-Apr-17 10:57 mpyl/utilities/docker/__init__.py
--rw-r--r--  2.0 unx     1938 b- defN 24-Apr-17 10:57 mpyl/utilities/github/__init__.py
--rw-r--r--  2.0 unx     1034 b- defN 24-Apr-17 10:57 mpyl/utilities/helm/__init__.py
--rw-r--r--  2.0 unx     1566 b- defN 24-Apr-17 10:57 mpyl/utilities/jenkins/__init__.py
--rw-r--r--  2.0 unx     7910 b- defN 24-Apr-17 10:57 mpyl/utilities/jenkins/runner.py
--rw-r--r--  2.0 unx     1598 b- defN 24-Apr-17 10:57 mpyl/utilities/junit/__init__.py
--rw-r--r--  2.0 unx      318 b- defN 24-Apr-17 10:57 mpyl/utilities/logging/__init__.py
--rw-r--r--  2.0 unx     1003 b- defN 24-Apr-17 10:57 mpyl/utilities/parallel/__init__.py
--rw-r--r--  2.0 unx      870 b- defN 24-Apr-17 10:57 mpyl/utilities/pyaml_env/__init__.py
--rw-r--r--  2.0 unx    13604 b- defN 24-Apr-17 10:57 mpyl/utilities/repo/__init__.py
--rw-r--r--  2.0 unx     1589 b- defN 24-Apr-17 10:57 mpyl/utilities/sbt/__init__.py
--rw-r--r--  2.0 unx     2573 b- defN 24-Apr-17 10:57 mpyl/utilities/subprocess/__init__.py
--rw-r--r--  2.0 unx      868 b- defN 24-Apr-17 10:57 mpyl/utilities/yaml/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/LICENSE
--rw-r--r--  2.0 unx     6195 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       35 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        5 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     9930 b- defN 24-Apr-17 10:58 mpyl-1.6.4.dist-info/RECORD
-112 files, 1452099 bytes uncompressed, 242166 bytes compressed:  83.3%
+Zip file size: 265316 bytes, number of entries: 120
+-rw-r--r--  2.0 unx     1278 b- defN 24-Apr-22 08:39 mpyl/__init__.py
+-rw-r--r--  2.0 unx      215 b- defN 24-Apr-22 08:39 mpyl/__main__.py
+-rw-r--r--  2.0 unx     7535 b- defN 24-Apr-22 08:39 mpyl/build.py
+-rw-r--r--  2.0 unx      304 b- defN 24-Apr-22 08:39 mpyl/constants.py
+-rw-r--r--  2.0 unx    21281 b- defN 24-Apr-22 08:39 mpyl/project.py
+-rw-r--r--  2.0 unx      997 b- defN 24-Apr-22 08:39 mpyl/project_execution.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-22 08:39 mpyl/py.typed
+-rw-r--r--  2.0 unx     1038 b- defN 24-Apr-22 08:39 mpyl/run_plan.py
+-rw-r--r--  2.0 unx     2370 b- defN 24-Apr-22 08:39 mpyl/validation.py
+-rw-r--r--  2.0 unx       60 b- defN 24-Apr-22 08:39 mpyl/artifacts/__init__.py
+-rw-r--r--  2.0 unx     9222 b- defN 24-Apr-22 08:39 mpyl/artifacts/build_artifacts.py
+-rw-r--r--  2.0 unx     3512 b- defN 24-Apr-22 08:39 mpyl/cli/__init__.py
+-rw-r--r--  2.0 unx    18054 b- defN 24-Apr-22 08:39 mpyl/cli/build.py
+-rw-r--r--  2.0 unx      614 b- defN 24-Apr-22 08:39 mpyl/cli/health.py
+-rw-r--r--  2.0 unx     2417 b- defN 24-Apr-22 08:39 mpyl/cli/meta_info.py
+-rw-r--r--  2.0 unx     8536 b- defN 24-Apr-22 08:39 mpyl/cli/projects.py
+-rw-r--r--  2.0 unx     7944 b- defN 24-Apr-22 08:39 mpyl/cli/repository.py
+-rw-r--r--  2.0 unx       34 b- defN 24-Apr-22 08:39 mpyl/cli/commands/__init__.py
+-rw-r--r--  2.0 unx      425 b- defN 24-Apr-22 08:39 mpyl/cli/commands/build/__init__.py
+-rw-r--r--  2.0 unx     1261 b- defN 24-Apr-22 08:39 mpyl/cli/commands/build/artifacts.py
+-rw-r--r--  2.0 unx     4524 b- defN 24-Apr-22 08:39 mpyl/cli/commands/build/jenkins.py
+-rw-r--r--  2.0 unx       38 b- defN 24-Apr-22 08:39 mpyl/cli/commands/health/__init__.py
+-rw-r--r--  2.0 unx     8248 b- defN 24-Apr-22 08:39 mpyl/cli/commands/health/checks.py
+-rw-r--r--  2.0 unx       52 b- defN 24-Apr-22 08:39 mpyl/cli/commands/projects/__init__.py
+-rw-r--r--  2.0 unx     1771 b- defN 24-Apr-22 08:39 mpyl/cli/commands/projects/formatting.py
+-rw-r--r--  2.0 unx     6356 b- defN 24-Apr-22 08:39 mpyl/cli/commands/projects/lint.py
+-rw-r--r--  2.0 unx      659 b- defN 24-Apr-22 08:39 mpyl/cli/commands/projects/upgrade.py
+-rw-r--r--  2.0 unx      620 b- defN 24-Apr-22 08:39 mpyl/projects/__init__.py
+-rw-r--r--  2.0 unx     2006 b- defN 24-Apr-22 08:39 mpyl/projects/find.py
+-rw-r--r--  2.0 unx    12121 b- defN 24-Apr-22 08:39 mpyl/projects/versioning.py
+-rw-r--r--  2.0 unx      339 b- defN 24-Apr-22 08:39 mpyl/projects/releases/releases.txt
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-22 08:39 mpyl/reporting/__init__.py
+-rw-r--r--  2.0 unx       76 b- defN 24-Apr-22 08:39 mpyl/reporting/formatting/__init__.py
+-rw-r--r--  2.0 unx     5797 b- defN 24-Apr-22 08:39 mpyl/reporting/formatting/markdown.py
+-rw-r--r--  2.0 unx     1340 b- defN 24-Apr-22 08:39 mpyl/reporting/formatting/text.py
+-rw-r--r--  2.0 unx     1139 b- defN 24-Apr-22 08:39 mpyl/reporting/targets/__init__.py
+-rw-r--r--  2.0 unx     8932 b- defN 24-Apr-22 08:39 mpyl/reporting/targets/github.py
+-rw-r--r--  2.0 unx     9568 b- defN 24-Apr-22 08:39 mpyl/reporting/targets/jira.py
+-rw-r--r--  2.0 unx     8064 b- defN 24-Apr-22 08:39 mpyl/reporting/targets/slack.py
+-rw-r--r--  2.0 unx    11326 b- defN 24-Apr-22 08:39 mpyl/schema/k8s_api_core.schema.yml
+-rw-r--r--  2.0 unx    14606 b- defN 24-Apr-22 08:39 mpyl/schema/mpyl_config.schema.yml
+-rw-r--r--  2.0 unx    24934 b- defN 24-Apr-22 08:39 mpyl/schema/project.schema.yml
+-rw-r--r--  2.0 unx     3296 b- defN 24-Apr-22 08:39 mpyl/schema/run_properties.schema.yml
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-22 08:39 mpyl/stages/__init__.py
+-rw-r--r--  2.0 unx    12300 b- defN 24-Apr-22 08:39 mpyl/stages/discovery.py
+-rw-r--r--  2.0 unx     6456 b- defN 24-Apr-22 08:39 mpyl/steps/__init__.py
+-rw-r--r--  2.0 unx     2686 b- defN 24-Apr-22 08:39 mpyl/steps/collection.py
+-rw-r--r--  2.0 unx     8465 b- defN 24-Apr-22 08:39 mpyl/steps/models.py
+-rw-r--r--  2.0 unx     4320 b- defN 24-Apr-22 08:39 mpyl/steps/run.py
+-rw-r--r--  2.0 unx     3620 b- defN 24-Apr-22 08:39 mpyl/steps/run_properties.py
+-rw-r--r--  2.0 unx     9692 b- defN 24-Apr-22 08:39 mpyl/steps/steps.py
+-rw-r--r--  2.0 unx       80 b- defN 24-Apr-22 08:39 mpyl/steps/build/__init__.py
+-rw-r--r--  2.0 unx     5034 b- defN 24-Apr-22 08:39 mpyl/steps/build/docker_build.py
+-rw-r--r--  2.0 unx     1195 b- defN 24-Apr-22 08:39 mpyl/steps/build/echo.py
+-rw-r--r--  2.0 unx     2192 b- defN 24-Apr-22 08:39 mpyl/steps/build/post_docker_build.py
+-rw-r--r--  2.0 unx     2714 b- defN 24-Apr-22 08:39 mpyl/steps/build/sbt.py
+-rw-r--r--  2.0 unx      884 b- defN 24-Apr-22 08:39 mpyl/steps/build/skip.py
+-rw-r--r--  2.0 unx       82 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/__init__.py
+-rw-r--r--  2.0 unx     2172 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/bpm_deploy.py
+-rw-r--r--  2.0 unx     7596 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/dagster.py
+-rw-r--r--  2.0 unx     1078 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/echo.py
+-rw-r--r--  2.0 unx     1533 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/ephemeral_docker_deploy.py
+-rw-r--r--  2.0 unx     3221 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/kubernetes.py
+-rw-r--r--  2.0 unx     1115 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/kubernetes_job.py
+-rw-r--r--  2.0 unx     1188 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/kubernetes_spark_job.py
+-rw-r--r--  2.0 unx     2442 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/bpm/__init__.py
+-rw-r--r--  2.0 unx     1731 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/bpm/camunda_modeler_client.py
+-rw-r--r--  2.0 unx     2280 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/bpm/cluster.py
+-rw-r--r--  2.0 unx     1818 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/bpm/modeler.py
+-rw-r--r--  2.0 unx    11433 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/__init__.py
+-rw-r--r--  2.0 unx    28949 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/chart.py
+-rw-r--r--  2.0 unx     1276 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/deploy_config.py
+-rw-r--r--  2.0 unx     5080 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/helm.py
+-rw-r--r--  2.0 unx     1594 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/rancher.py
+-rw-r--r--  2.0 unx     4868 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/__init__.py
+-rw-r--r--  2.0 unx     3368 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/dagster.py
+-rw-r--r--  2.0 unx     2260 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/prometheus.py
+-rw-r--r--  2.0 unx      616 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/sealed_secret.py
+-rw-r--r--  2.0 unx     5895 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/spark.py
+-rw-r--r--  2.0 unx     2818 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/traefik.py
+-rw-r--r--  2.0 unx   582312 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml
+-rw-r--r--  2.0 unx    39299 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml
+-rw-r--r--  2.0 unx   168371 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml
+-rw-r--r--  2.0 unx   151469 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml
+-rw-r--r--  2.0 unx    11703 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml
+-rw-r--r--  2.0 unx    42950 b- defN 24-Apr-22 08:39 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml
+-rw-r--r--  2.0 unx       90 b- defN 24-Apr-22 08:39 mpyl/steps/postdeploy/__init__.py
+-rw-r--r--  2.0 unx     8519 b- defN 24-Apr-22 08:39 mpyl/steps/postdeploy/cypress_test.py
+-rw-r--r--  2.0 unx       78 b- defN 24-Apr-22 08:39 mpyl/steps/test/__init__.py
+-rw-r--r--  2.0 unx     1574 b- defN 24-Apr-22 08:39 mpyl/steps/test/after_test.py
+-rw-r--r--  2.0 unx     4153 b- defN 24-Apr-22 08:39 mpyl/steps/test/before_test.py
+-rw-r--r--  2.0 unx     4652 b- defN 24-Apr-22 08:39 mpyl/steps/test/dockertest.py
+-rw-r--r--  2.0 unx     1937 b- defN 24-Apr-22 08:39 mpyl/steps/test/echo.py
+-rw-r--r--  2.0 unx     3636 b- defN 24-Apr-22 08:39 mpyl/steps/test/sbt.py
+-rw-r--r--  2.0 unx      878 b- defN 24-Apr-22 08:39 mpyl/steps/test/skip.py
+-rw-r--r--  2.0 unx      346 b- defN 24-Apr-22 08:39 mpyl/utilities/__init__.py
+-rw-r--r--  2.0 unx     3502 b- defN 24-Apr-22 08:39 mpyl/utilities/bpm/__init__.py
+-rw-r--r--  2.0 unx      953 b- defN 24-Apr-22 08:39 mpyl/utilities/cypress/__init__.py
+-rw-r--r--  2.0 unx     1068 b- defN 24-Apr-22 08:39 mpyl/utilities/dagster/__init__.py
+-rw-r--r--  2.0 unx    13237 b- defN 24-Apr-22 08:39 mpyl/utilities/docker/__init__.py
+-rw-r--r--  2.0 unx     1938 b- defN 24-Apr-22 08:39 mpyl/utilities/github/__init__.py
+-rw-r--r--  2.0 unx     1034 b- defN 24-Apr-22 08:39 mpyl/utilities/helm/__init__.py
+-rw-r--r--  2.0 unx     2786 b- defN 24-Apr-22 08:39 mpyl/utilities/http_client/__init__.py
+-rw-r--r--  2.0 unx      692 b- defN 24-Apr-22 08:39 mpyl/utilities/http_client/exceptions.py
+-rw-r--r--  2.0 unx     1566 b- defN 24-Apr-22 08:39 mpyl/utilities/jenkins/__init__.py
+-rw-r--r--  2.0 unx     7910 b- defN 24-Apr-22 08:39 mpyl/utilities/jenkins/runner.py
+-rw-r--r--  2.0 unx     1598 b- defN 24-Apr-22 08:39 mpyl/utilities/junit/__init__.py
+-rw-r--r--  2.0 unx      318 b- defN 24-Apr-22 08:39 mpyl/utilities/logging/__init__.py
+-rw-r--r--  2.0 unx     1003 b- defN 24-Apr-22 08:39 mpyl/utilities/parallel/__init__.py
+-rw-r--r--  2.0 unx      870 b- defN 24-Apr-22 08:39 mpyl/utilities/pyaml_env/__init__.py
+-rw-r--r--  2.0 unx    13604 b- defN 24-Apr-22 08:39 mpyl/utilities/repo/__init__.py
+-rw-r--r--  2.0 unx     1589 b- defN 24-Apr-22 08:39 mpyl/utilities/sbt/__init__.py
+-rw-r--r--  2.0 unx     2573 b- defN 24-Apr-22 08:39 mpyl/utilities/subprocess/__init__.py
+-rw-r--r--  2.0 unx      868 b- defN 24-Apr-22 08:39 mpyl/utilities/yaml/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6195 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx       35 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        5 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10669 b- defN 24-Apr-22 08:40 mpyl-1.6.5.dist-info/RECORD
+120 files, 1474481 bytes uncompressed, 248350 bytes compressed:  83.2%
```

## zipnote {}

```diff
@@ -168,14 +168,17 @@
 
 Filename: mpyl/steps/build/skip.py
 Comment: 
 
 Filename: mpyl/steps/deploy/__init__.py
 Comment: 
 
+Filename: mpyl/steps/deploy/bpm_deploy.py
+Comment: 
+
 Filename: mpyl/steps/deploy/dagster.py
 Comment: 
 
 Filename: mpyl/steps/deploy/echo.py
 Comment: 
 
 Filename: mpyl/steps/deploy/ephemeral_docker_deploy.py
@@ -186,14 +189,26 @@
 
 Filename: mpyl/steps/deploy/kubernetes_job.py
 Comment: 
 
 Filename: mpyl/steps/deploy/kubernetes_spark_job.py
 Comment: 
 
+Filename: mpyl/steps/deploy/bpm/__init__.py
+Comment: 
+
+Filename: mpyl/steps/deploy/bpm/camunda_modeler_client.py
+Comment: 
+
+Filename: mpyl/steps/deploy/bpm/cluster.py
+Comment: 
+
+Filename: mpyl/steps/deploy/bpm/modeler.py
+Comment: 
+
 Filename: mpyl/steps/deploy/k8s/__init__.py
 Comment: 
 
 Filename: mpyl/steps/deploy/k8s/chart.py
 Comment: 
 
 Filename: mpyl/steps/deploy/k8s/deploy_config.py
@@ -267,14 +282,17 @@
 
 Filename: mpyl/steps/test/skip.py
 Comment: 
 
 Filename: mpyl/utilities/__init__.py
 Comment: 
 
+Filename: mpyl/utilities/bpm/__init__.py
+Comment: 
+
 Filename: mpyl/utilities/cypress/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/dagster/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/docker/__init__.py
@@ -282,14 +300,20 @@
 
 Filename: mpyl/utilities/github/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/helm/__init__.py
 Comment: 
 
+Filename: mpyl/utilities/http_client/__init__.py
+Comment: 
+
+Filename: mpyl/utilities/http_client/exceptions.py
+Comment: 
+
 Filename: mpyl/utilities/jenkins/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/jenkins/runner.py
 Comment: 
 
 Filename: mpyl/utilities/junit/__init__.py
@@ -312,26 +336,26 @@
 
 Filename: mpyl/utilities/subprocess/__init__.py
 Comment: 
 
 Filename: mpyl/utilities/yaml/__init__.py
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/LICENSE
+Filename: mpyl-1.6.5.dist-info/LICENSE
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/METADATA
+Filename: mpyl-1.6.5.dist-info/METADATA
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/WHEEL
+Filename: mpyl-1.6.5.dist-info/WHEEL
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/entry_points.txt
+Filename: mpyl-1.6.5.dist-info/entry_points.txt
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/top_level.txt
+Filename: mpyl-1.6.5.dist-info/top_level.txt
 Comment: 
 
-Filename: mpyl-1.6.4.dist-info/RECORD
+Filename: mpyl-1.6.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mpyl/project.py

```diff
@@ -394,14 +394,25 @@
         hosts = values.get("hosts")
         return Traefik(
             hosts=(list(map(TraefikHost.from_config, hosts) if hosts else []))
         )
 
 
 @dataclass(frozen=True)
+class BPM:
+    project_id: str
+
+    @staticmethod
+    def from_config(values: dict):
+        return BPM(
+            project_id=values.get("projectId", ""),
+        )
+
+
+@dataclass(frozen=True)
 class Docker:
     host_name: str
 
     @staticmethod
     def from_config(values: dict):
         return Docker(host_name=values["hostName"])
 
@@ -433,28 +444,31 @@
 @dataclass(frozen=True)
 class Deployment:
     namespace: Optional[str]
     properties: Properties
     kubernetes: Optional[Kubernetes]
     dagster: Optional[Dagster]
     traefik: Optional[Traefik]
+    bpm: Optional[BPM]
 
     @staticmethod
     def from_config(values: dict):
         props = values.get("properties")
         kubernetes = values.get("kubernetes")
         dagster = values.get("dagster")
         traefik = values.get("traefik")
+        bpm = values.get("bpm")
 
         return Deployment(
             namespace=values.get("namespace"),
             properties=Properties.from_config(props) if props else None,
             kubernetes=Kubernetes.from_config(kubernetes) if kubernetes else None,
             dagster=Dagster.from_config(dagster) if dagster else None,
             traefik=Traefik.from_config(traefik) if traefik else None,
+            bpm=BPM.from_config(bpm) if bpm else None,
         )
 
 
 @dataclass(frozen=True)
 class ProjectName:
     name: str
     namespace: Optional[str]
@@ -503,14 +517,20 @@
     @property
     def dagster(self) -> Dagster:
         if self.deployment is None or self.deployment.dagster is None:
             raise KeyError(f"Project '{self.name}' does not have dagster configuration")
         return self.deployment.dagster
 
     @property
+    def bpm(self) -> BPM:
+        if self.deployment is None or self.deployment.bpm is None:
+            raise KeyError(f"Project '{self.name}' does not have bpm configuration")
+        return self.deployment.bpm
+
+    @property
     def resources(self) -> Resources:
         return self.kubernetes.resources
 
     @property
     def job(self) -> Job:
         if self.kubernetes.job is None:
             raise KeyError(
```

## mpyl/project_execution.py

```diff
@@ -1,23 +1,35 @@
 """This module contains the ProjectExecution class."""
-import uuid
+
 from dataclasses import dataclass
+from typing import Optional
 
 from .project import Project
 
 
 @dataclass(frozen=True)
 class ProjectExecution:
     project: Project
-    cache_key: str
+    hashed_changes: Optional[str]
     cached: bool
 
     @staticmethod
-    def always_run(project: Project):
-        """Create a ProjectExecution for a project that will always run, regardless of caching"""
+    def create(project: Project, cached: bool, hashed_changes: Optional[str] = None):
+        if cached:
+            return ProjectExecution.skip(project, hashed_changes)
+        return ProjectExecution.run(project, hashed_changes)
+
+    @staticmethod
+    def skip(project: Project, hashed_changes: Optional[str] = None):
+        return ProjectExecution(
+            project=project, hashed_changes=hashed_changes, cached=True
+        )
+
+    @staticmethod
+    def run(project: Project, hashed_changes: Optional[str] = None):
         return ProjectExecution(
-            project=project, cache_key=uuid.uuid4().hex, cached=False
+            project=project, hashed_changes=hashed_changes, cached=False
         )
 
     @property
     def name(self):
         return self.project.name
```

## mpyl/run_plan.py

```diff
@@ -1,12 +1,12 @@
 """This module contains the RunPlan class."""
 
 from dataclasses import dataclass
 
-from .project import Stage
+from .project import Project, Stage
 from .project_execution import ProjectExecution
 
 
 @dataclass(frozen=True)
 class RunPlan:
     plan: dict[Stage, set[ProjectExecution]]
 
@@ -21,7 +21,18 @@
         self.plan.update({stage: executions})
 
     def update(self, run_plan: "RunPlan"):
         self.plan.update(run_plan.plan)
 
     def items(self):
         return self.plan.items()
+
+    def for_stage(self, stage: Stage) -> "RunPlan":
+        return RunPlan({stage: self.get(stage)})
+
+    def for_projects(self, projects: set[Project]):
+        return RunPlan(
+            {
+                stage: {e for e in executions if e.project in projects}
+                for stage, executions in self.plan.items()
+            }
+        )
```

## mpyl/cli/build.py

```diff
@@ -205,15 +205,14 @@
         )
         sys.exit(1)
 
     run_properties = construct_run_properties(
         config=obj.config,
         properties=obj.run_properties,
         cli_parameters=parameters,
-        sequential=sequential,
     )
     run_result = run_mpyl(
         run_properties=run_properties, cli_parameters=parameters, reporter=None
     )
 
     Path(RUN_ARTIFACTS_FOLDER).mkdir(parents=True, exist_ok=True)
     run_result_file = Path(RUN_ARTIFACTS_FOLDER) / f"run_result-{uuid.uuid4()}.pickle"
```

## mpyl/projects/releases/releases.txt

```diff
@@ -44,8 +44,9 @@
 1.4.20
 1.5.0
 1.5.1
 1.6.0
 1.6.1
 1.6.2
 1.6.3
-1.6.4
+1.6.4
+1.6.5
```

## mpyl/schema/mpyl_config.schema.yml

```diff
@@ -28,14 +28,16 @@
         "$ref": "#/definitions/Jenkins"
       sbt:
         "$ref": "#/definitions/Sbt"
       slack:
         "$ref": "#/definitions/Slack"
       jira:
         "$ref": "#/definitions/Jira"
+      camunda:
+        "$ref": "#/definitions/Camunda"
     required:
       - vcs
       - docker
     title: MPyL global configuration
   Whitelists:
     type: object
     required:
@@ -424,14 +426,75 @@
         type: string
       ticketPattern:
         type: [ string, null ]
         default: '[A-Za-z]{2,}-\d+'
         description: 'A pattern that extracts a ticket number from the branch name'
     required:
       - site
+  Camunda:
+    type: object
+    properties:
+      modelerAPI:
+        type: object
+        properties:
+          baseUrl:
+            type: string
+          tokenUrl:
+            type: string
+        required: [ "baseUrl", "tokenUrl" ]
+      modelerCredentials:
+        type: object
+        properties:
+          clientId:
+            type: string
+          clientSecret:
+            type: string
+          grantType:
+            type: string
+          audience:
+            type: string
+        required: [ "clientId", "clientSecret", "grantType", "audience" ]
+      zeebeCredentials:
+        type: object
+        properties:
+          pr:
+            "$ref": "#/definitions/CamundaCluster"
+          test:
+            "$ref": "#/definitions/CamundaCluster"
+          acceptance:
+            "$ref": "#/definitions/CamundaCluster"
+          production:
+            "$ref": "#/definitions/CamundaCluster"
+        required: [ 'pr', 'test', 'acceptance', 'production' ]
+      camundaDeploymentPath:
+        type: object
+        properties:
+          diagramResourcesPath:
+            type: string
+          dockerDirectoryPath:
+            type: string
+          dockerFilePath:
+            type: string
+          bpmProjectPath:
+            type: string
+        required: [ 'diagramResourcesPath', 'dockerDirectoryPath', 'dockerFilePath', 'bpmProjectPath' ]
+    required:
+      - modelerAPI
+      - modelerCredentials
+      - zeebeCredentials
+      - camundaDeploymentPath
+  CamundaCluster:
+    type: object
+    properties:
+      clusterId:
+        type: string
+      clientId:
+        type: string
+      clientSecret:
+        type: string
   Dagster:
     title: Dagster
     type: object
     additionalProperties: false
     properties:
       baseNamespace:
         description: "Namespace that contains dagster instances"
```

## mpyl/schema/project.schema.yml

```diff
@@ -83,14 +83,15 @@
           - Echo Kubernetes Deploy
           - Kubernetes Job Deploy
           - Kubernetes Job Template Deploy
           - Kubernetes Spark Job Deploy
           - Renew Lets Encrypt Deploy
           - Helm Deploy
           - Dagster Deploy
+          - BPM Diagram Deploy
       postdeploy:
         description: Additional steps that can be done after the project has been deployed.
         examples:
           - TriggerJenkinsJob PostDeploy
         type: string
         enum:
           - TriggerJenkinsJob PostDeploy
@@ -267,14 +268,25 @@
             items:
               $ref: '#/definitions/envSecret'
           repo:
             description: Absolute path to Dagster repository py-file
             type: string
             examples:
               - /python/my_project/dagster/repo.py
+      bpm:
+        additionalProperties: false
+        type: object
+        required:
+          - projectId
+        properties:
+          projectId:
+            description: >-
+              project Id where diagram is stored in Camunda Modeler,
+              you can find this value from Camunda Saas url when open the project
+            type: string
     minProperties: 1
     required:
       - namespace
   postdeployment:
     type: object
     additionalProperties: false
     properties:
```

## mpyl/stages/discovery.py

```diff
@@ -89,244 +89,309 @@
 
 
 def is_project_cached_for_stage(
     logger: logging.Logger,
     project: str,
     stage: str,
     output: Optional[Output],
-    cache_key: str,
+    hashed_changes: Optional[str],
 ) -> bool:
     cached = False
 
     if stage == deploy.STAGE_NAME:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because this stage is never cached"
+            f"Project {project} will execute stage {stage} because this stage is never cached"
         )
     elif output is None:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because there is no previous run"
+            f"Project {project} will execute stage {stage} because there is no previous run"
         )
     elif not output.success:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because the previous run was not successful"
+            f"Project {project} will execute stage {stage} because the previous run was not successful"
         )
     elif output.produced_artifact is None:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because there was no artifact in the previous run"
+            f"Project {project} will execute stage {stage} because there was no artifact in the previous run"
         )
     elif not output.produced_artifact.hash:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because there is no cache key in the previous run"
+            f"Project {project} will execute stage {stage} because there are no hashed changes for the previous run"
         )
-    elif output.produced_artifact.hash != cache_key:
+    elif not hashed_changes:
         logger.debug(
-            f"Project {project} will execute stage {stage} again because its content changed since the previous run"
+            f"Project {project} will execute stage {stage} because there are no hashed changes for the current run"
         )
+    elif output.produced_artifact.hash != hashed_changes:
         logger.debug(
-            f"Hash of contents for previous run: {output.produced_artifact.hash}"
+            f"Project {project} will execute stage {stage} because its content changed since the previous run"
         )
-        logger.debug(f"Hash of contents for current run:  {cache_key}")
+        logger.debug(
+            f"Hashed changes for the previous run: {output.produced_artifact.hash}"
+        )
+        logger.debug(f"Hashed changes for the current run:  {hashed_changes}")
     else:
         logger.debug(
             f"Project {project} will skip stage {stage} because its content did not change since the previous run"
         )
-        logger.debug(f"Hash of contents for current run: {cache_key}")
+        logger.debug(f"Hashed changes for the current run: {hashed_changes}")
         cached = True
 
     return cached
 
 
-def hashed_changes(files: set[str]) -> str:
+def _hash_changes_in_project(
+    logger: logging.Logger,
+    project: Project,
+    changeset: Changeset,
+) -> Optional[str]:
+    files_to_hash = set(
+        filter(
+            lambda changed_file: file_belongs_to_project(logger, project, changed_file),
+            changeset.files_touched(status={"A", "M", "R"}),
+        )
+    )
+
+    if len(files_to_hash) == 0:
+        return None
+
     sha256 = hashlib.sha256()
 
-    for changed_file in sorted(files):
+    for changed_file in sorted(files_to_hash):
         with open(changed_file, "rb") as file:
             while True:
                 data = file.read(65536)
                 if not data:
                     break
                 sha256.update(data)
 
     return sha256.hexdigest()
 
 
-def _to_project_execution(
+def to_project_executions(
     logger: logging.Logger,
-    project: Project,
+    projects: set[Project],
     stage: str,
     changeset: Changeset,
-    steps: Optional[StepsCollection],
-) -> Optional[ProjectExecution]:
-    if project.stages.for_stage(stage) is None:
-        return None
-
-    is_any_dependency_modified = any(
-        is_dependency_modified(logger, project, stage, changed_file, steps)
-        for changed_file in changeset.files_touched()
-    )
-    is_project_modified = any(
-        file_belongs_to_project(logger, project, changed_file)
-        for changed_file in changeset.files_touched()
-    )
-
-    if is_project_modified:
-        files_to_hash = set(
-            filter(
-                lambda changed_file: file_belongs_to_project(
-                    logger, project, changed_file
-                ),
-                changeset.files_touched(status={"A", "M", "R"}),
-            )
+) -> set[ProjectExecution]:
+    def to_project_execution(
+        project: Project,
+    ) -> ProjectExecution:
+        hashed_changes = _hash_changes_in_project(
+            logger=logger, project=project, changeset=changeset
         )
 
-        if len(files_to_hash) == 0:
-            cache_key = changeset.sha
-            logger.debug(
-                f"Project {project.name}: using git revision as cache key: {cache_key}"
-            )
-        else:
-            cache_key = hashed_changes(files=files_to_hash)
-            logger.debug(
-                f"Project {project.name}: using hash of modified files as cache key: {cache_key}"
-            )
-
-    elif is_any_dependency_modified:
-        cache_key = changeset.sha
-        logger.debug(
-            f"Project {project.name}: using git revision as cache key: {cache_key}"
+        return ProjectExecution.create(
+            project=project,
+            cached=is_project_cached_for_stage(
+                logger=logger,
+                project=project.name,
+                stage=stage,
+                output=Output.try_read(project.target_path, stage),
+                hashed_changes=hashed_changes,
+            ),
+            hashed_changes=hashed_changes,
         )
-    else:
-        return None
 
-    return ProjectExecution(
-        project=project,
-        cache_key=cache_key,
-        cached=is_project_cached_for_stage(
-            logger=logger,
-            project=project.name,
-            stage=stage,
-            output=Output.try_read(project.target_path, stage),
-            cache_key=cache_key,
-        ),
-    )
+    return set(map(to_project_execution, projects))
 
 
 def find_projects_to_execute(
     logger: logging.Logger,
     all_projects: set[Project],
     stage: str,
     changeset: Changeset,
     steps: Optional[StepsCollection],
 ) -> set[ProjectExecution]:
-    maybe_execution_projects = set(
-        map(
-            lambda project: _to_project_execution(
-                logger, project, stage, changeset, steps
-            ),
-            all_projects,
+    def build_project_execution(
+        project: Project,
+    ) -> Optional[ProjectExecution]:
+        if project.stages.for_stage(stage) is None:
+            return None
+
+        is_any_dependency_modified = any(
+            is_dependency_modified(logger, project, stage, changed_file, steps)
+            for changed_file in changeset.files_touched()
+        )
+        is_project_modified = any(
+            file_belongs_to_project(logger, project, changed_file)
+            for changed_file in changeset.files_touched()
         )
-    )
+
+        if is_any_dependency_modified:
+            logger.debug(
+                f"Project {project} will execute stage {stage} because a dependency was modified"
+            )
+
+            if is_project_modified:
+                hashed_changes = _hash_changes_in_project(
+                    logger=logger, project=project, changeset=changeset
+                )
+            else:
+                hashed_changes = None
+
+            return ProjectExecution.run(project, hashed_changes)
+
+        if is_project_modified:
+            hashed_changes = _hash_changes_in_project(
+                logger=logger, project=project, changeset=changeset
+            )
+
+            return ProjectExecution.create(
+                project=project,
+                cached=is_project_cached_for_stage(
+                    logger=logger,
+                    project=project.name,
+                    stage=stage,
+                    output=Output.try_read(project.target_path, stage),
+                    hashed_changes=hashed_changes,
+                ),
+                hashed_changes=hashed_changes,
+            )
+
+        return None
+
     return {
         project_execution
-        for project_execution in maybe_execution_projects
+        for project_execution in map(build_project_execution, all_projects)
         if project_execution is not None
     }
 
 
-def create_run_plan(  # pylint: disable=too-many-arguments, too-many-locals
+# pylint: disable=too-many-arguments
+def create_run_plan(
     logger: logging.Logger,
     repository: Repository,
     all_projects: set[Project],
     all_stages: list[Stage],
     build_all: bool,
     local: bool,
+    selected_projects: set[Project],
     tag: Optional[str] = None,
-    selected_stage: Optional[str] = None,
-    selected_projects: Optional[str] = None,
-    sequential: Optional[bool] = False,
+    selected_stage: Optional[Stage] = None,
 ) -> RunPlan:
-    if selected_projects:
-        projects_list = selected_projects.split(",")
+    run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.pickle"
 
-    run_plan: RunPlan = RunPlan.empty()
+    existing_run_plan = _load_existing_run_plan(logger, run_plan_file)
+    if existing_run_plan:
+        return _filter_existing_run_plan(
+            run_plan=existing_run_plan,
+            selected_stage=selected_stage,
+            selected_projects=selected_projects,
+        )
+
+    run_plan = _discover_run_plan(
+        logger=logger,
+        repository=repository,
+        all_projects=all_projects,
+        all_stages=all_stages,
+        build_all=build_all,
+        local=local,
+        selected_projects=selected_projects,
+        selected_stage=selected_stage,
+        tag=tag,
+    )
 
-    run_plan_file = Path(RUN_ARTIFACTS_FOLDER) / "run_plan.pickle"
-    if sequential and not build_all and not selected_projects:
-        if not run_plan_file.is_file():
-            logger.warning(
-                f"Sequential flag is passed, but no previous run plan found: {run_plan_file}"
-            )
-        else:
-            logger.info(f"Loading existing run plan: {run_plan_file}")
-            return _load_existing_run_plan(
-                run_plan_file=run_plan_file, selected_stage=selected_stage
-            )
+    _store_run_plan(logger, run_plan, run_plan_file)
+    return run_plan
 
-    elif run_plan_file.is_file():
-        logger.info(f"Deleting previous run plan file: {run_plan_file}")
-        run_plan_file.unlink()
 
+def _filter_existing_run_plan(
+    run_plan: RunPlan,
+    selected_stage: Optional[Stage],
+    selected_projects: set[Project],
+) -> RunPlan:
+    filtered_run_plan = run_plan
+
+    if selected_stage:
+        filtered_run_plan = filtered_run_plan.for_stage(selected_stage)
+
+    if selected_projects:
+        filtered_run_plan = filtered_run_plan.for_projects(selected_projects)
+
+    return filtered_run_plan
+
+
+# pylint: disable=too-many-arguments
+def _discover_run_plan(
+    logger: logging.Logger,
+    repository: Repository,
+    all_projects: set[Project],
+    all_stages: list[Stage],
+    build_all: bool,
+    local: bool,
+    selected_projects: set[Project],
+    selected_stage: Optional[Stage],
+    tag: Optional[str] = None,
+) -> RunPlan:
     logger.info("Discovering run plan...")
+    run_plan: RunPlan = RunPlan.empty()
+    changeset = _get_changes(repository, local, tag)
+
     for stage in all_stages:
-        if selected_stage and selected_stage != stage.name:
+        if selected_stage and stage != selected_stage:
             continue
 
-        if build_all or selected_projects:
-            if selected_projects:
-                all_projects = set(
-                    filter(lambda p: p.name in projects_list, all_projects)
-                )
-            projects = for_stage(all_projects, stage)
-            project_executions = {ProjectExecution.always_run(p) for p in projects}
-        else:
-            steps = StepsCollection(logger=logging.getLogger())
-            changes_in_branch = (
-                _get_changes(repository, local, tag)
-                if not selected_projects or build_all
-                else []
+        if build_all:
+            project_executions = to_project_executions(
+                logger=logger,
+                projects=for_stage(all_projects, stage),
+                stage=stage.name,
+                changeset=changeset,
             )
-
-            project_executions = find_projects_to_execute(
-                logger, all_projects, stage.name, changes_in_branch, steps
+        elif selected_projects:
+            project_executions = to_project_executions(
+                logger=logger,
+                projects=for_stage(selected_projects, stage),
+                stage=stage.name,
+                changeset=changeset,
             )
-            logger.debug(
-                f"Invalidated projects for stage {stage.name}: {[p.name for p in project_executions]}"
+        else:
+            project_executions = find_projects_to_execute(
+                logger=logger,
+                all_projects=all_projects,
+                stage=stage.name,
+                changeset=changeset,
+                steps=StepsCollection(logger=logging.getLogger()),
             )
 
+        logger.debug(
+            f"Will execute projects for stage {stage.name}: {[p.name for p in project_executions]}"
+        )
         run_plan.add_stage(stage, project_executions)
 
-    if not selected_stage and not build_all and not selected_projects:
-        os.makedirs(os.path.dirname(run_plan_file), exist_ok=True)
-        with open(run_plan_file, "wb") as file:
-            logger.info(f"Storing run plan in: {run_plan_file}")
-            pickle.dump(run_plan, file, pickle.HIGHEST_PROTOCOL)
-
     return run_plan
 
 
 def for_stage(projects: set[Project], stage: Stage) -> set[Project]:
-    return set(filter(lambda p: p.stages.for_stage(stage.name), projects))
+    return {p for p in projects if p.stages.for_stage(stage.name)}
 
 
 def _get_changes(repo: Repository, local: bool, tag: Optional[str] = None):
     if local:
         return repo.changes_in_branch_including_local()
     if tag:
         return repo.changes_in_tagged_commit(tag)
 
     return repo.changes_in_branch()
 
 
 def _load_existing_run_plan(
-    run_plan_file: Path, selected_stage: Optional[str]
-) -> RunPlan:
-    with open(run_plan_file, "rb") as file:
-        full_run_plan: RunPlan = pickle.load(file)
-        if selected_stage:
-            return RunPlan(
-                {
-                    stage: project_executions
-                    for stage, project_executions in full_run_plan.items()
-                    if stage.name == selected_stage
-                }
-            )
-        return full_run_plan
+    logger: logging.Logger,
+    run_plan_file_path: Path,
+) -> Optional[RunPlan]:
+    if run_plan_file_path.is_file():
+        logger.info(f"Loading existing run plan: {run_plan_file_path}")
+        with open(run_plan_file_path, "rb") as file:
+            return pickle.load(file)
+    return None
+
+
+def _store_run_plan(
+    logger: logging.Logger,
+    run_plan: RunPlan,
+    run_plan_file_path: Path,
+):
+    os.makedirs(os.path.dirname(run_plan_file_path), exist_ok=True)
+    with open(run_plan_file_path, "wb") as file:
+        logger.info(f"Storing run plan in: {run_plan_file_path}")
+        pickle.dump(run_plan, file, pickle.HIGHEST_PROTOCOL)
```

## mpyl/steps/models.py

```diff
@@ -277,11 +277,11 @@
 
 def input_to_artifact(
     artifact_type: ArtifactType, step_input: Input, spec: ArtifactSpec
 ):
     return Artifact(
         artifact_type=artifact_type,
         revision=step_input.run_properties.versioning.revision,
-        hash=step_input.project_execution.cache_key,
+        hash=step_input.project_execution.hashed_changes,
         producing_step=step_input.project_execution.name,
         spec=spec,
     )
```

## mpyl/steps/run_properties.py

```diff
@@ -16,15 +16,14 @@
     config: dict,
     properties: dict,
     cli_parameters: MpylCliParameters = MpylCliParameters(),
     run_plan: Optional[RunPlan] = None,
     all_projects: Optional[set[Project]] = None,
     root_dir: Path = Path(""),
     explain_run_plan: bool = False,
-    sequential: bool = False,
 ) -> RunProperties:
     tag = cli_parameters.tag or properties["build"]["versioning"].get("tag")
     if all_projects is None or run_plan is None:
         with Repository(RepoConfig.from_config(config)) as repo:
             if all_projects is None:
                 project_paths = repo.find_projects()
                 all_projects = set(
@@ -51,15 +50,14 @@
                 run_plan = _create_run_plan(
                     cli_parameters=cli_parameters,
                     all_projects=all_projects,
                     all_stages=stages,
                     explain_run_plan=explain_run_plan,
                     repo=repo,
                     tag=tag,
-                    sequential=sequential,
                 )
 
     if cli_parameters.local:
         return RunProperties.for_local_run(
             config=config,
             run_plan=run_plan,
             revision=repo.get_sha,
@@ -82,25 +80,37 @@
 def _create_run_plan(
     cli_parameters: MpylCliParameters,
     all_projects: set[Project],
     all_stages: list[Stage],
     explain_run_plan: bool,
     repo: Repository,
     tag: Optional[str] = None,
-    sequential: Optional[bool] = False,
 ):
     run_plan_logger = logging.getLogger("mpyl")
     if explain_run_plan:
         run_plan_logger.setLevel("DEBUG")
 
+    if cli_parameters.stage:
+        selected_stage = next(
+            (stage for stage in all_stages if stage.name == cli_parameters.stage), None
+        )
+    else:
+        selected_stage = None
+
+    if cli_parameters.projects:
+        selected_projects = {
+            p for p in all_projects if p.name in cli_parameters.projects.split(",")
+        }
+    else:
+        selected_projects = set()
+
     return create_run_plan(
         logger=run_plan_logger,
         repository=repo,
         all_projects=all_projects,
         all_stages=all_stages,
         tag=tag,
         local=cli_parameters.local,
         build_all=cli_parameters.all,
-        selected_stage=cli_parameters.stage,
-        selected_projects=cli_parameters.projects,
-        sequential=sequential,
+        selected_stage=selected_stage,
+        selected_projects=selected_projects,
     )
```

## mpyl/steps/build/post_docker_build.py

```diff
@@ -41,15 +41,15 @@
 
         full_image_path = docker_registry_path(docker_registry, image_name)
         artifact = Artifact(
             artifact_type=ArtifactType.DOCKER_IMAGE,
             revision=properties.versioning.revision,
             producing_step=self.meta.name,
             spec=DockerImageSpec(image=full_image_path),
-            hash=step_input.project_execution.cache_key,
+            hash=step_input.project_execution.hashed_changes,
         )
 
         if step_input.dry_run:
             return Output(
                 success=True,
                 message=f"Dry run. Not pushing {image_name} to {docker_registry.host_name}",
                 produced_artifact=artifact,
```

## mpyl/steps/postdeploy/cypress_test.py

```diff
@@ -1,8 +1,9 @@
 """ Step that runs relevant cypress tests in the post deploy stage """
+
 import os
 from logging import Logger
 
 from kubernetes.config.kube_config import KubeConfigMerger
 from python_on_whales import docker, Container, DockerException
 
 from . import STAGE_NAME
```

## mpyl/steps/test/sbt.py

```diff
@@ -33,40 +33,16 @@
             produced_artifact=ArtifactType.JUNIT_TESTS,
             required_artifact=ArtifactType.NONE,
             before=IntegrationTestBefore(logger),
             after=IntegrationTestAfter(logger),
         )
 
     def _test(self, step_input: Input, sbt_config: SbtConfig) -> Output:
-        command_compile = self._construct_sbt_command(
-            project_name=step_input.project_execution.name,
-            config=sbt_config,
-            compile_test=True,
-        )
-        compile_outcome = custom_check_output(
-            logger=self._logger, command=command_compile, use_print=True
-        )
-        if not compile_outcome.success:
-            if sbt_config.test_with_coverage:
-                coverage_off_command = sbt_config.to_command(
-                    sbt_config.test_with_client, ["coverageOff"]
-                )
-                custom_check_output(
-                    logger=self._logger, command=coverage_off_command, use_print=True
-                )
-            return Output(
-                success=False,
-                message=f"Tests failed to compile for {step_input.project_execution.name}",
-                produced_artifact=None,
-            )
-
         command_test = self._construct_sbt_command(
-            project_name=step_input.project_execution.name,
-            config=sbt_config,
-            compile_test=False,
+            project_name=step_input.project_execution.name, config=sbt_config
         )
         run_outcome = custom_check_output(
             logger=self._logger, command=command_test, use_print=True
         )
         artifact = self._extract_test_report(
             step_input.project_execution.project, step_input
         )
@@ -86,32 +62,30 @@
 
         if test_result.produced_artifact:
             spec = cast(JunitTestSpec, test_result.produced_artifact.spec)
             suite = to_test_suites(spec)
             summary = sum_suites(suite)
             spec.test_results_summary = summary
             return Output(
-                success=summary.is_success,
+                success=test_result.success and summary.is_success,
                 message=f"Tests results produced for {project.name} ({summary})",
                 produced_artifact=test_result.produced_artifact,
             )
 
         return test_result
 
     @staticmethod
-    def _construct_sbt_command(
-        project_name: str, config: SbtConfig, compile_test: bool
-    ):
+    def _construct_sbt_command(project_name: str, config: SbtConfig):
         command = list(
             filter(
                 None,
                 [
                     f"project {project_name}",
                     "coverageOn" if config.test_with_coverage else None,
-                    f"test{':compile' if compile_test else ''}",
+                    "test",
                     "coverageOff" if config.test_with_coverage else None,
                 ],
             )
         )
         return config.to_command(config.test_with_client, command)
 
     @staticmethod
```

## Comparing `mpyl-1.6.4.dist-info/LICENSE` & `mpyl-1.6.5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mpyl-1.6.4.dist-info/METADATA` & `mpyl-1.6.5.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mpyl
-Version: 1.6.4
+Version: 1.6.5
 Summary: Modular Pipeline Library
 Home-page: https://vandebron.github.io/mpyl
 Author: Vandebron Energie BV
 Project-URL: Documentation, https://vandebron.github.io/mpyl
 Project-URL: Source, https://github.com/Vandebron/mpyl
 Project-URL: Tracker, https://github.com/Vandebron/mpyl/issues
 Classifier: Topic :: Software Development :: Build Tools
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: mpyl Version: 1.6.4 Summary: Modular Pipeline
+Metadata-Version: 2.1 Name: mpyl Version: 1.6.5 Summary: Modular Pipeline
 Library Home-page: https://vandebron.github.io/mpyl Author: Vandebron Energie
 BV Project-URL: Documentation, https://vandebron.github.io/mpyl Project-URL:
 Source, https://github.com/Vandebron/mpyl Project-URL: Tracker, https://
 github.com/Vandebron/mpyl/issues Classifier: Topic :: Software Development ::
 Build Tools Classifier: Topic :: Utilities Classifier: Development Status :: 4
 - Beta Classifier: Environment :: Console Classifier: Intended Audience ::
 Developers Classifier: Operating System :: OS Independent Classifier:
```

## Comparing `mpyl-1.6.4.dist-info/RECORD` & `mpyl-1.6.5.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 mpyl/__init__.py,sha256=pJ0OOmWsxvMr3JRqfC24VUpEiI6vwJppOTf-G6-nTHI,1278
 mpyl/__main__.py,sha256=2c9boQJDUA6b8p2umOych7HHlwmBdmsIQDLZcE_pBdo,215
 mpyl/build.py,sha256=X2iMzm2LpReVOu4A506nsvz56AQvUHWrzfw4QgodvCc,7535
 mpyl/constants.py,sha256=jIcpytI9cpIB7dFo87ct8G6BaGevsDC2pNpvXE0ugkA,304
-mpyl/project.py,sha256=3Aem-0Us8gYy2AwyxccXm5OlD0yxhyHNKUZtk62Wp9o,20750
-mpyl/project_execution.py,sha256=d6QR3NKJGz_UnIXe5K7psbPfjqHTW66EKuarenGtsEE,574
+mpyl/project.py,sha256=kGVtqf5bVjiR1OS8ZYJs-32luLLQWabF5Hia-dNobIs,21281
+mpyl/project_execution.py,sha256=6e8YTqEgbvReZMAqC4WUzghlQA_3EKwqHLPhsem7lCw,997
 mpyl/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mpyl/run_plan.py,sha256=BfvVk_DhQfIwhx7QZYAJJdLAtA9Y4F-xwxH_fSWeRL4,681
+mpyl/run_plan.py,sha256=mtuhBo4JisQYmsUuM4PbT5Jtz7smE8UzsaFE44Oee1Q,1038
 mpyl/validation.py,sha256=Cps5Y_kPD2asBY13wG4G1xxrrM2Xi_EWr37sFXK9f18,2370
 mpyl/artifacts/__init__.py,sha256=0KjD4BVqH5WVi9Rma5R6FsJN9hAcc5u-gNRRYUn945s,60
 mpyl/artifacts/build_artifacts.py,sha256=qm7E2fvSgApCDXZskMPf0ATk1pGBooegFsoyM957k2A,9222
 mpyl/cli/__init__.py,sha256=W0cVhHL0_HrQqtyg-t-TCoD5eYnpcSCNPU8sR6p8eO4,3512
-mpyl/cli/build.py,sha256=xtOAa6fvYyPagNROeMWXTvWDS_WGbbNf8w_TZL6-oF8,18085
+mpyl/cli/build.py,sha256=24DENNe4Lwe5CZK06vw9ztOKGjGOZfTLDvmnCsXF12M,18054
 mpyl/cli/health.py,sha256=z0dMZcVM0tZlKKHzCX5qgdIczaDaPx1_JI4SCh6S91A,614
 mpyl/cli/meta_info.py,sha256=a4-M9D_aaddup4Z2gF34WkmsHBzxQECJb8UNit0q6Po,2417
 mpyl/cli/projects.py,sha256=uIbUSKaa-dWNuiClyy3nVi4r6DUbzP5n8cUZeVD_c7M,8536
 mpyl/cli/repository.py,sha256=YcKDL0IBtCcnClsdRNGJDL_wSQ2SjEib_yE-h2t3bwc,7944
 mpyl/cli/commands/__init__.py,sha256=DaL5q4ibFJT7EMlgcQBSpAaaQNiBqnSJZ2WIKtPzLJk,34
 mpyl/cli/commands/build/__init__.py,sha256=yvYblWUNG8vEvU-CT2NSNX6aLUxcKU1Ndw2ZHWZez50,425
 mpyl/cli/commands/build/artifacts.py,sha256=RfprLCJtEzyoy0QlCvyK7boOu8uPZBzGlmUbnStYzHk,1261
@@ -24,48 +24,53 @@
 mpyl/cli/commands/projects/__init__.py,sha256=ZJtZz1CwcJerE3K-wz6DeWzxBUKP5gEHgQTkwpnvXhY,52
 mpyl/cli/commands/projects/formatting.py,sha256=Ph1ZMF1XE880XOXM54G_3MEFjjZN4wabQOtmJLJXR9E,1771
 mpyl/cli/commands/projects/lint.py,sha256=t3HICC4jYjT4UgjjFhI0riJJO58QWFCK1n5cpqInhtY,6356
 mpyl/cli/commands/projects/upgrade.py,sha256=4TUv-IyNzmL-Ehc1R05zAyU6gvOILnaoYs9ASVZjHt4,659
 mpyl/projects/__init__.py,sha256=31HPF5jDZK5UkQT8Zw0V0QSJLqzp8f2zFiWd-QkDjRE,620
 mpyl/projects/find.py,sha256=gQwSu4F0FzWDn6YJWBDuo97OZfL3Fj_iQKAARX0b6oY,2006
 mpyl/projects/versioning.py,sha256=vFet-3hp-toe_tDRYQ-9M321UXzBGvuAS4oLMXVvPTg,12121
-mpyl/projects/releases/releases.txt,sha256=9C6eZU_B60YR7q4OJ02M0KH8pkxnsHgh1gczw7c6hrQ,333
+mpyl/projects/releases/releases.txt,sha256=i3n_1u0ArgH8_jtXHnGFh-P0Q_ZOYbJaXTFoVsO8wVU,339
 mpyl/reporting/__init__.py,sha256=vRvt_67opWXCfe_zYZChT-YhjoPOahAjLagoaVzOcFM,92
 mpyl/reporting/formatting/__init__.py,sha256=GAvYJpHT2SMQxjiLCSqFy57PNWsGI_Ow2bFnA8cX08k,76
 mpyl/reporting/formatting/markdown.py,sha256=ZoM3Ep_m-wsqP3afTq8pybk3G7viP4MRFPD-fLtmEjI,5797
 mpyl/reporting/formatting/text.py,sha256=-_GFebP6KffJA1eS3RvGFHsH7k8EOkkvjVcnRlqNFYo,1340
 mpyl/reporting/targets/__init__.py,sha256=31UWFweqJqvlE3WZBb2CMBIAnmJJRZpVBwpW-ma4MzA,1139
 mpyl/reporting/targets/github.py,sha256=IOjnWqV6QO6wAWMuVB8Nbxws7U9sUqBhgVJSJEzFkgE,8932
 mpyl/reporting/targets/jira.py,sha256=PE60WdezLBEvq8rbcpQEg0XgQ8MFmFX8agtB9SolISc,9568
 mpyl/reporting/targets/slack.py,sha256=fcvywqWCkdzVl0YWe1jGGq52jC5ePxQg9Qw8_YByTjk,8064
 mpyl/schema/k8s_api_core.schema.yml,sha256=9bPsgRIHa2AvJjXUDqSjEgIpU-tb2YXAAt64wD4YqBo,11326
-mpyl/schema/mpyl_config.schema.yml,sha256=nn-NPQdOVYEbYq1tmVDKrDNWFt64dMRcDuGNHGxl9WQ,12912
-mpyl/schema/project.schema.yml,sha256=kLAh9BbwCyKzUIw-iDCl20kpVgJtvqLl0xioPuOuoJM,24550
+mpyl/schema/mpyl_config.schema.yml,sha256=ZFS0BvFecyqZEyXu0QoSSPq2KIpWTLiyiZAGG5fFvTQ,14606
+mpyl/schema/project.schema.yml,sha256=CMDT-P4aEOkqJx2Z_pmC_V9r1PtA8D1NwT39l-NeCBk,24934
 mpyl/schema/run_properties.schema.yml,sha256=hsBJcz9_n9PBAYbSSWsOvJdPIrhJv_B9JQdx0lVfUf4,3296
 mpyl/stages/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-mpyl/stages/discovery.py,sha256=y_oFPz06oCkVyU9bpiR1TsCvFTcgdf89D_vB-HZB2h4,10713
+mpyl/stages/discovery.py,sha256=aDo8z2N9Ceix_kPt8FMVPw4OTkbbayLdjpt8ADbFfNc,12300
 mpyl/steps/__init__.py,sha256=CwtgCMMbTJZjIiu4RVZonfEpqwMb2WqU4nHnqA-TCEM,6456
 mpyl/steps/collection.py,sha256=12848xJvrCuNBtf7U33EHw733BuTTZPAZzSOW0PSoX0,2686
-mpyl/steps/models.py,sha256=oBjp7gti7k4AnuuLLqzI4TwCD4OVbyYmxnxfusxR7BE,8460
+mpyl/steps/models.py,sha256=fcpbUKupe-sXEjgxWSxUG4rohpogL8EvBF2P4EKtbGE,8465
 mpyl/steps/run.py,sha256=3xn3rRczDh5l5P4YU9Bu9SO0pE1-jU1F1vE1rKTdfq4,4320
-mpyl/steps/run_properties.py,sha256=-2KDiMuVS8W81we3Yq6vC77s8wohh1bpnDS1c0OPB6Y,3376
+mpyl/steps/run_properties.py,sha256=hNZ2CssSFCXJHfAzOx3u5AEind5UKXplfh8WgUPMKbo,3620
 mpyl/steps/steps.py,sha256=-mvIAYw9DdpvXNXjhiM7LqJxAfOHtPQRQndxw8MqOeg,9692
 mpyl/steps/build/__init__.py,sha256=Q5BL1Bv5PrZkYBNbQvVNTL-n4Xq88qwtc3PtYunrc5c,80
 mpyl/steps/build/docker_build.py,sha256=6HZnL9PtdXAFVfblwf9R9E-_GzaE2K4xWICPV3YOY0E,5034
 mpyl/steps/build/echo.py,sha256=T5uJ0L43bVNZenJtVr4j0HgIMDr10v5Oaypu9W1VHG8,1195
-mpyl/steps/build/post_docker_build.py,sha256=7qzghmLCf8OJ_BDOKRwVPOZbVcknWOrZ2p958uJjA94,2187
+mpyl/steps/build/post_docker_build.py,sha256=aWlGo9ib4pGJwme6m97t5ORvuWNYSQAo0ssLMo_qjzI,2192
 mpyl/steps/build/sbt.py,sha256=riIyv5tY3hQdCXVbxsxzGoPMIG_0CsNY5EAsqOsyNvs,2714
 mpyl/steps/build/skip.py,sha256=71QJYYjJ5HL8Q2a9pB8ai9mTzTrL7yWQ_-DD2pLWRao,884
 mpyl/steps/deploy/__init__.py,sha256=PApoomqJGBtOt-08vVKjHVJTs2JHRWWF93Y2wFI0lN0,82
+mpyl/steps/deploy/bpm_deploy.py,sha256=iicjNYYhY7QL5JVENQrk2Dgduzjvd2r1b0qyGXa6jdg,2172
 mpyl/steps/deploy/dagster.py,sha256=wpb5FAait7ZXvjucf0ZlAnrELsQwmr5Y23SLwODQ1ZM,7596
 mpyl/steps/deploy/echo.py,sha256=Z6iL3icoxteiFWQkTppHfQAuP7B18lcu3ZJZqg6ssaM,1078
 mpyl/steps/deploy/ephemeral_docker_deploy.py,sha256=Wvz5C5CNaD0jdMTj8LZgZ325Ih0NeRl8_o8mc1Y8RQI,1533
 mpyl/steps/deploy/kubernetes.py,sha256=HzsLU7Ucowr2D_PIYFTPFADXTHDPdJF-g4N639h6mz4,3221
 mpyl/steps/deploy/kubernetes_job.py,sha256=r2pBuEMJ-WOcfHH3HZzQ5wG3tqwGSBnbB5ByapbwQvw,1115
 mpyl/steps/deploy/kubernetes_spark_job.py,sha256=_PJXQtnQ4TRgQj73vWEw6W6kIxD2DYCCo2Z0jjppfy4,1188
+mpyl/steps/deploy/bpm/__init__.py,sha256=PHHUkyRXkVEuJhcRDlazefAGmm4WaoK8akYlD3nDJ7E,2442
+mpyl/steps/deploy/bpm/camunda_modeler_client.py,sha256=soUEuALHeOTcZZv5P955TK_1O7S44Of7nVnO_CES8xw,1731
+mpyl/steps/deploy/bpm/cluster.py,sha256=0z0LxiwnVEGQD3cxBJlZt87wztXiyz1LBLt-6P_lnTQ,2280
+mpyl/steps/deploy/bpm/modeler.py,sha256=0rhWFwvhW2Zoe9Qm-oeAROC55WDxHcrFgGNBJPRvyWw,1818
 mpyl/steps/deploy/k8s/__init__.py,sha256=l5RxShdkdXs2nTTNK7GvWmciTyqwvuPhDV2-dERjLUY,11433
 mpyl/steps/deploy/k8s/chart.py,sha256=K0pPYS6NfNxLtDZMhNZk2Cdz3PeZCrm46VWjKthtx6k,28949
 mpyl/steps/deploy/k8s/deploy_config.py,sha256=haNB4oBieRLUVgFTCB-J1xcYJSaCX3EeqeqSCDvvSJ0,1276
 mpyl/steps/deploy/k8s/helm.py,sha256=VQ474ZRpwPvQS9XtILEWdoZdtHV_Q7GhCmNoSFL7lXQ,5080
 mpyl/steps/deploy/k8s/rancher.py,sha256=lJsPWM0l9EWH7YkH4QO6Hk38ZigQ42V7EHNmOvEDw5k,1594
 mpyl/steps/deploy/k8s/resources/__init__.py,sha256=Kn31han_zOgVMW9ElN47YEqi4RlZG63LJcklISxl4Ew,4868
 mpyl/steps/deploy/k8s/resources/dagster.py,sha256=NuN_EMduakIEIEv-c2i-cI0lfHXjlxDVCszIo3gQvNc,3368
@@ -76,37 +81,40 @@
 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_prometheuses.schema.yml,sha256=INuTN4VRA-Po6u4t66wrXArRcT32eQVEinK1KkdPuGA,582312
 mpyl/steps/deploy/k8s/resources/schema/monitoring.coreos.com_servicemonitors.schema.yml,sha256=MguUs6tReq8CAwS5OSmR125IgBlUQbD3bGJ8O_YAfBc,39299
 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_scheduledsparkapplications.schema.yml,sha256=jTo3LZklRCZ1L7JZbUdcmhDWhk3VDJhrDz_OTHNUm58,168371
 mpyl/steps/deploy/k8s/resources/schema/sparkoperator.k8s.io_sparkapplications.schema.yml,sha256=s1rMobinpB3aXI1ONcuTMGLMIRRQ_qZrZtQTYZHcDFU,151469
 mpyl/steps/deploy/k8s/resources/schema/traefik.ingress.schema.yml,sha256=3Oc1awM23acMS36kqpbfqwx6D8Sft4FnL8abNLgcwBI,11703
 mpyl/steps/deploy/k8s/resources/schema/traefik.middleware.schema.yml,sha256=6QCi1F9LJ3cgmwaPBV8dWFvbXb2B5huKvfp4Pa1hoBw,42950
 mpyl/steps/postdeploy/__init__.py,sha256=PDEwBgNjPl89w-5trIH25y0xY6wF3gG9Lw6HI_QA6MY,90
-mpyl/steps/postdeploy/cypress_test.py,sha256=VK8cPe8zFr386TuUeSixj_vBk-sZEr7PvIRoHRIJCgI,8518
+mpyl/steps/postdeploy/cypress_test.py,sha256=kGil5Hq4QPODVxDgMZioVXxaSzT4plkZw8ii__uLEVg,8519
 mpyl/steps/test/__init__.py,sha256=AhufNFmq3Rjn9ztt_qivyNdL6oHbSy5wbww-r9LOa5Q,78
 mpyl/steps/test/after_test.py,sha256=VCVWogXbuyaKOMu8jjOJWpZovBU7r4DgFSZQPY0xUIA,1574
 mpyl/steps/test/before_test.py,sha256=RgoNlwnzWM8O7cOPR6rE7_Z8E6M6cYmXFFuU9Au4wtI,4153
 mpyl/steps/test/dockertest.py,sha256=aXITeWyZR14v4cGiCd-hE-5efyjnnXcfI7Rjn28rpCM,4652
 mpyl/steps/test/echo.py,sha256=0wfvRbmyFIHvrPjSzlVRGCzAvaTOFbFJzWqIQs3obLQ,1937
-mpyl/steps/test/sbt.py,sha256=Q-E_uC1R_lEmAF0VJqDKDDljVDh4kvrVtX1i6TUc4OY,4622
+mpyl/steps/test/sbt.py,sha256=KxMLcHIN72oEV3j3hn8O3X-IHycap3BY-omxXDTzrGc,3636
 mpyl/steps/test/skip.py,sha256=WNoF2MXBH8sBgc0gVo5Ityc753vIFtMjKpiPwLOIlOM,878
 mpyl/utilities/__init__.py,sha256=-FhhMEriPoXTlrxyF9D48XpgjRfRy_KeLGkGAUsqre8,346
+mpyl/utilities/bpm/__init__.py,sha256=LgTBb_e--XZ3107RVe1pZ6K5uThPidbFG4wZN0vKINM,3502
 mpyl/utilities/cypress/__init__.py,sha256=VQZtP7hiFhRNr0jIAutomuL0yjdEY1mWQLqhzC1ZRVA,953
 mpyl/utilities/dagster/__init__.py,sha256=33zcIJaNyeXAy-o_eDcRjLOLsc8wKquxj4Ffppvgu_c,1068
 mpyl/utilities/docker/__init__.py,sha256=JIw48UE0yfCryvTEYWsbHC87Zl-JVPmztNdgKW1BkmE,13237
 mpyl/utilities/github/__init__.py,sha256=9BGCEw96HOHkQGWpZmBbmPrduCH2Zj0idNKLeZPQK2A,1938
 mpyl/utilities/helm/__init__.py,sha256=PrC06s5DEQ7USeMwxzJqzrNtzGaIroD79fqjMpuqa-c,1034
+mpyl/utilities/http_client/__init__.py,sha256=BftHKe-qd1ymDjfb5gmQm3MeLfix-iQqUpz1-Pjnq8M,2786
+mpyl/utilities/http_client/exceptions.py,sha256=Uy1y2FvxwstvlNJXsoxp0O9hqxm09iq9Ao9XjI3gpoE,692
 mpyl/utilities/jenkins/__init__.py,sha256=8MCGdWLCX0oU2FhIfYHM2GIxPKX9lr6sUgdCpSbz_zE,1566
 mpyl/utilities/jenkins/runner.py,sha256=Vfc92TeYVtG_o5oOtTZSW1x91m1JEmkFC1SyvVyrpTs,7910
 mpyl/utilities/junit/__init__.py,sha256=BYNX6l0NG_8RrRPUyKS6cqpEb2myXTzv2Z8nCej_CYg,1598
 mpyl/utilities/logging/__init__.py,sha256=CgcGcy44WdScwOo4ncONIUcm47EA1SUMZrXHe4qjepk,318
 mpyl/utilities/parallel/__init__.py,sha256=3pyODnVMj_ecFvzGgh6wmJn95XlxWi91pau3-6A_Hmo,1003
 mpyl/utilities/pyaml_env/__init__.py,sha256=NqinyF-ULX69X48pgLpcmm46JB0o2nPxERi5bruMs48,870
 mpyl/utilities/repo/__init__.py,sha256=__TP3vn7dAGLWVm-MfTaQKSdD8PxuIZKtQqxilTxmVw,13604
 mpyl/utilities/sbt/__init__.py,sha256=JJf1FU8JSyQhKaR78OEAup1VBXOLqNKf3tROtp54gAM,1589
 mpyl/utilities/subprocess/__init__.py,sha256=UeaVmVF1spnkLKnNWzF_9GMVM2WJ4WwOPeb2T6NdlAc,2573
 mpyl/utilities/yaml/__init__.py,sha256=gjNnyh_TwgOfGGIZa5hN5VzRibuzlo1L1dOHeCD1CW4,868
-mpyl-1.6.4.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-mpyl-1.6.4.dist-info/METADATA,sha256=N165AqR7QGGHINyKz-8brqsNs8rMXFpx95fLPFqyR64,6195
-mpyl-1.6.4.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-mpyl-1.6.4.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
-mpyl-1.6.4.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
-mpyl-1.6.4.dist-info/RECORD,,
+mpyl-1.6.5.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+mpyl-1.6.5.dist-info/METADATA,sha256=N-HsfkH9Z_3-1pTyucLxiO6hig1H4-FzqGEZ2jJi0hI,6195
+mpyl-1.6.5.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+mpyl-1.6.5.dist-info/entry_points.txt,sha256=Jf4zjGLsiokFbaQ2dfX9AC5Bu3kp7zxrBOAzErmAYs8,35
+mpyl-1.6.5.dist-info/top_level.txt,sha256=xVSrrk0ECDxKYaW8mAyGy02yY8KhKlUSyzHaq9UDVNs,5
+mpyl-1.6.5.dist-info/RECORD,,
```

